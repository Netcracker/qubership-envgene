---
  name: Link Checker

  on:
    push: null
    repository_dispatch: null
    workflow_dispatch: null
    pull_request:
      branches: [main]
      types:
        [opened, reopened, synchronize]
    workflow_call: null
  permissions:
    contents: read
  jobs:
    linkChecker:
      runs-on: ubuntu-latest
      steps:
        - uses: actions/checkout@v4

        - name: Restore lychee cache
          uses: actions/cache@v4
          id: restore-cache
          with:
            path: .lycheecache
            key: cache-lychee-${{ github.sha }}
            restore-keys: cache-lychee-

        - name: Link Checker (External Links)
          id: lychee
          uses: lycheeverse/lychee-action@v2
          with:
            args: >-
              './**/*.md'
              --verbose
              --no-progress
              --include-fragments
              --root-dir .
              --user-agent 'Mozilla/5.0 (X11; Linux x86_64) Chrome/134.0.0.0'
              --retry-wait-time 60
              --max-retries 8
              --accept 100..=103,200..=299,429
              --cookie-jar cookies.json
              --exclude-all-private
              --max-concurrency 4
              --cache
              --cache-exclude-status '429, 500..502'
              --max-cache-age 1d
            format: markdown
            fail: true

        - name: Link Checker (Local Files)
          run: |
            python3 << 'EOF'
            import re
            import os
            from pathlib import Path
            
            errors = []
            
            # Find all markdown files
            for md_file in Path('.').rglob('*.md'):
                with open(md_file, 'r', encoding='utf-8') as f:
                    content = f.read()
                    base_dir = md_file.parent
                    
                    # Find all markdown links [text](path#anchor)
                    pattern = r'\[([^\]]+)\]\(([^)]+)\)'
                    for match in re.finditer(pattern, content):
                        link_text = match.group(1)
                        link_path = match.group(2)
                        
                        # Skip HTTP/HTTPS links
                        if link_path.startswith('http://') or link_path.startswith('https://'):
                            continue
                        
                        # Skip mailto links
                        if link_path.startswith('mailto:'):
                            continue
                        
                        # Split path and anchor
                        if '#' in link_path:
                            file_path, anchor = link_path.split('#', 1)
                        else:
                            file_path = link_path
                            anchor = None
                        
                        # Resolve relative path
                        if file_path.startswith('/'):
                            # Absolute path from repo root
                            target_file = Path('.' + file_path)
                        else:
                            # Relative path
                            target_file = (base_dir / file_path).resolve()
                        
                        # Check if file exists
                        if not target_file.exists():
                            errors.append(f"{md_file}:{content[:match.start()].count(chr(10)) + 1}: File not found: {link_path}")
                            continue
                        
                        # Check anchor if present
                        if anchor:
                            with open(target_file, 'r', encoding='utf-8') as tf:
                                target_content = tf.read()
                                # Convert anchor to heading format (lowercase, replace - with spaces, then back to -)
                                anchor_normalized = anchor.lower().replace('_', '-')
                                # Check for heading with this anchor
                                heading_pattern = r'^#+\s+.*$'
                                headings = re.findall(heading_pattern, target_content, re.MULTILINE)
                                anchor_found = False
                                for heading in headings:
                                    heading_id = re.sub(r'[^\w\s-]', '', heading.lower())
                                    heading_id = re.sub(r'[-\s]+', '-', heading_id).strip('-')
                                    if anchor_normalized in heading_id or heading_id.endswith(anchor_normalized):
                                        anchor_found = True
                                        break
                                if not anchor_found:
                                    errors.append(f"{md_file}:{content[:match.start()].count(chr(10)) + 1}: Anchor not found: {link_path}")
            
            if errors:
                print("Found broken local links:")
                for error in errors:
                    print(f"  {error}")
                exit(1)
            else:
                print("All local links are valid!")
            EOF